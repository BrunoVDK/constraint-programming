\section{Sudoku}

Sudoku is a well-known puzzle game which needs no introduction. It is classically modelled as a constraint satisfaction problem through the use of \texttt{all\_different} constraints on rows, columns and blocks. Such global inequalities tend to improve upon the use of binary inequalities. \texttt{ECLiPSe} and \texttt{CHR} implementations are available in \texttt{/sudoku/model/classic.pl} and in \texttt{/sudoku/chr/classic.pl} respectively. The constraint generating code is fairly trivial and needn't be detailed here. \\\par

There are several other ways one could model Sudoku. The widely cited study by Helmut Simonis and subsequent studies (that of Laburthe in particular) provide some ideas. Four \textit{`dual'} models, two approaches based on a boolean characterisation, a combination of models provided by Laburthe[REF], a model enforcing the singular occurrence of every value in every row, column and block, as well as a model with nothing but channeling constraints were considered. The models are implemented in the \texttt{/sudoku/model} directory. Tests were run on the provided puzzles\footnote{\texttt{/sudoku/benchmarks/benchmarks.pl} provides automatic benchmarking code.} as well as some minimum puzzles provided by Gordon Royle. These are puzzles with a minimal amount of pre-filled cells (17 to be precise[McGuire, 2014]), which does not mean that they are harder to solve. \\\par

The dual models each have an $N\times N$ variable array. Whereas in the classic viewpoint the rows, columns and values correspond to those of the input puzzle, every dual model switches their roles. The first two models that were considered switch the role of rows or columns with those of values. In the third dual model every row and column of the array corresponds to a block and a position. In the fourth model every row represents a block, every column a value and every value a position within a block. Every of these models made it harder to implement the necessary constraints, usually necessitating the use of auxiliary variables together with appropriate channeling constraints.\\\par  

Laburthe presents various rules that can be used to resolve Sudoku puzzles, after which he details some models that he links to the rules. He ends up proposing a model for every level of difficulty of the input puzzle. Our implementation saw a reduction in the number of backtracks but an increase in running time. \\\par

The boolean models include the natural combined model [REF] and a more intuitive characterisation resembling an integer programming model (we used \texttt{ic\_global:occurrences/3} instead of sums). Both of them have $N\times N\times N$ boolean variables $b_{rcv}$ which are true if the cell at row $r$ and column $c$ holds the value $v$. The natural combined model was cumbersome to implement and performed badly. It was introduced together with an algorithm after which it was tailored.\\\par

The last two models were found to be the most performant. The first makes use of the \texttt{ic\_global:occurrences/3} constraint to make every value occur just once in every row, column and block. 
\par The second one generates nothing but channeling constraints. It has been demonstrated that this can provide good results despite such constraints being less `tight' than \texttt{all\_different} constraints[REF ROSSI]. When Dotu discussed it he was considering QuasiGroups[REF]. In \texttt{sudoku/model/channeling.pl} the idea was extended to Sudoku puzzles by making use of three instead of two dual models (since blocks need to be considered as well). The variant in which channeling constraints between all models (one primal, three dual) are generated performed better than the one in which only channeling constraints between the primal and every dual model were used. These variants are analogous to what Dotu referred to as \textit{`trichanneling'} and \textit{`bichanneling'}. \\\par

\subsection{Experiments}

Number of backtracks and running time for most of the models are displayed in table 1. Removal of \textit{`big'} (\texttt{all\_different}) constraints led to increases in runtime as predicted by Demoen[REF]. \\\par

>> Maybe do some redundant constraints (those two from Simonis) but now the focus lies on CHR and understanding the whole thing to explain results. Probably good enough to use dual3 for the experiments because it makes channeling easier.